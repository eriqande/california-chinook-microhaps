---
title: "Assessing Power of the California Microhap Baseline for PBT and relationship inference"
author: "Eric C. Anderson"
date: "Last Updated: `r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
start_time <- Sys.time()
```



```{r}
if(exists("snakemake")) {
  input_list <- snakemake@input
  output_list <- snakemake@output
} else {
  input_list <- list(
    final_baseline = "data/subRoSA_baseline_rubias_loci_renamed_July_2024.csv.gz",
    pop_labels = "inputs/reference-collection-names.csv",
    locus_info = "inputs/Calif-Chinook-Amplicon-Panel-Information.csv"
  )
  output_list <- list(
    ckmr_figure = "results/ckmr-sim-eval/fpr-fnr-figure.pdf",
    ckmr_figure_crop = "results/ckmr-sim-eval/fpr-fnr-figure-crop.pdf",
    ckmr_figure_tex = "tex/images/fpr-fnr-figure-crop.pdf",
    ckmr_comp = "results/ckmr-sim-eval/cmkr-comp-figure.pdf",
    ckmr_comp_crop = "results/ckmr-sim-eval/cmkr-comp-figure-crop.pdf",
    ckmr_comp_tex = "tex/images/cmkr-comp-figure-crop.pdf"
    
  )
}

# you can create the necessary output directories like this:
dump <- lapply(output_list, function(x)
  dir.create(dirname(x), recursive = TRUE, showWarnings = FALSE)
)
```


## Wrangle the data

```{r}
library(tidyverse)
library(CKMRsim)
library(readxl)
library(parallel)
library(grid)
library(gridExtra)

# get the full baseline with the new markers, etc.  We will toss out some
# non-winter Sacto fish of unknown provenance
full_base <- read_csv(input_list$final_baseline) 

# read the pop labels for proper sorting
pop_labels <- read_csv(input_list$pop_labels)

# rename those collections and repunits
full_base2 <- full_base %>%
  rename(old_name = collection) %>%
  select(-repunit) %>%
  left_join(pop_labels %>% select(old_name, collection, repunit, ckmr_sim_group), by = join_by(old_name)) %>%
  select(-old_name) %>%
  select(indiv, repunit, collection, sample_type, ckmr_sim_group, everything())


# after that, we can nest things into separate ckmr_sim_groups
ckmr_sim_nests <- full_base2 %>%
  group_by(ckmr_sim_group) %>%
  nest()


# now, we also want to get the genome positions of things.
# we take its position to be the start position of the amplicon
gen_coords <- read_csv(input_list$locus_info) %>%
  rename(Locus = AmpliconName, Chrom = Otsh_v2.0_chromosome, Pos = AmpliconStartPos) %>%
  select(Locus, Chrom, Pos)





```


## Now, a series of functions to operate on each nest and do CKMRsim things

```{r}
#' @param X a tibble like that nested in a single row of ckmr_sim_nests
#' @param GC2 essentially the gen_coords object from above
ckmr_afreqs_ready <- function(X, GC2) {
  tmp <- X %>%
    select(-(repunit:sample_type)) %>%
    pivot_longer(
      -indiv,
      names_to = c("Locus", "gene_copy"),
      values_to = "Allele",
      names_pattern = "^(.*)_([12])$"
    ) %>%
    filter(!is.na(Allele)) %>%
    count(Locus, Allele) %>%
    group_by(Locus) %>%
    filter(n() > 1) %>% # filter out monomorphic loci
    mutate(
      Freq = n / sum(n),
    ) %>%
    ungroup() %>%
    left_join(GC2, by = join_by(Locus)) %>%
    select(Chrom, Pos, Locus, Allele, Freq) %>%
    arrange(Pos, desc(Freq)) 
  
  no_pos_posse <- tmp %>% 
    filter(is.na(Chrom))
  
  if(nrow(no_pos_posse) > 0) {
    warning("Some loci without genomic positions: ", paste(unique(no_pos_posse$Locus), collapse = ", "), "\n\n")
    warning("Those loci were dropped, and the analysis should survive, but you should see what's up!")
  }
  
  # then, return thing without the no_pos_posse markers
  tmp %>%
    filter(!is.na(Chrom)) %>%
    mutate(
      AlleIdx = NA,
      LocIdx = NA
    ) %>%
    CKMRsim::reindex_markers()
  
}


# here is one to create a ckmr object.
# Y is simply the output of ckmr_afreqs_ready()
ckmr_create <- function(Y) {
  create_ckmr(
    D = Y,
    kappa_matrix = kappas[c("PO", "FS", "HS", "AN", "U"), ],
    ge_mod_assumed = ge_model_TGIE,
    ge_mod_true = ge_model_TGIE,
    ge_mod_assumed_pars_list = list(epsilon = 0.005),
    ge_mod_true_pars_list = list(epsilon = 0.005)
  )
}


# This does the simulate_Qij step and then also estimates the FPRs.
ckmr_simQ <- function(C, unlinked = FALSE, num_mc_samples = 1e5) {
  simulate_Qij(
    C,
    reps = num_mc_samples,  # 100,000 monte carlo samples by default
    calc_relats = c("PO", "FS", "HS", "AN", "U"),
    sim_relats = c("PO", "FS", "HS", "AN", "U"),
    unlinked = unlinked,
    pedigree_list = pedigrees
  )
}


```


And here is a function that does the above and then spits out some FPRs and FNRs:
```{r}

get_FPRs_and_FNRs <- function(X, GC2 = gen_coords) {
  
  Y <- ckmr_afreqs_ready(X, GC2)
  
  C <- ckmr_create(Y) 
  
  # throttle text output to console
  options(CKMRsim.discard_stdout = TRUE)
  options(CKMRsim.linkage_verbosity = 0)
  
  # Simulate some Q_ij's. Suppress output messages that the CKMRsim package
  # produces
  Q_link <- ckmr_simQ(C) #%>% suppressMessages()
  Q_unl <- ckmr_simQ(C, unlinked = TRUE) #%>% suppressMessages()
  
  # get FPRs and FNRs for a variety of relationships.  Return in a big tibble
  
  ret <- list(
    # first for resolving unrelated individuals from PO and FS (and HS, for which there is no hope!)
    all_v_unrel = mc_sample_simple(
      Q = Q_unl,
      Q_for_fnrs = Q_link,
      nu = c("PO", "FS", "HS"),
      de = "U",
      tr = "U",
      method = "IS",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    # then, vanilla MCMC to see how readily we can distinguish FS from PO,
    # and then, of course FS from HS and PO from A, etc.
    po_vs_fs = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "FS",
      tr = "FS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    fs_vs_po = mc_sample_simple(
      Q = Q_link,
      nu = c("FS"),
      de = "PO",
      tr = "PO",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    fs_vs_hs = mc_sample_simple(
      Q = Q_link,
      nu = c("FS"),
      de = "HS",
      tr = "HS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    po_vs_hs = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "HS",
      tr = "HS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    po_vs_an = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "AN",
      tr = "AN",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    )
  ) %>%
    bind_rows(.id = "what_it_was")
  
  ret
}


```


I tried ripping through everything using furrr::future_map() but that did not
actually do it in parallel.  So we are going to just mclapply it:

```{r}
set.seed(5)
tmp_list <- mclapply(
  X = ckmr_sim_nests$data, 
  FUN = function(x) get_FPRs_and_FNRs(x),
  mc.cores = 8
)

ckmr_sim_results <- tibble(
  ckmr_sim_nests,
  fprs = tmp_list
)
```


## Make a plot with all those results

```{r}
# unnest it
ckmr_sim_tib <- ckmr_sim_results %>%
  select(-data) %>%
  unnest(fprs) %>%
  ungroup()

# just print out the different scenarios simulated
ckmr_sim_tib %>%
  distinct(mc_method, numerator, denominator, true_relat)
```


Now, make a figure of those results.

```{r}
# first, try a simple way of categorizing the errors
error_types_tib <- tribble(
  ~"scenario", ~"Error Category",
  "IS-FS-U-U", "Mistaking U for FS",
  "IS-HS-U-U", "Mistaking U for HS",
  "IS-PO-U-U", "Mistaking U for PO",
  "vanilla-FS-HS-HS", "Mistaking HS for FS",
  "vanilla-FS-PO-PO", "Mistaking PO for FS",
  "vanilla-PO-AN-AN", "Mistaking AN for PO",
  "vanilla-PO-FS-FS", "Mistaking FS for PO",
  "vanilla-PO-HS-HS", "Mistaking HS for PO"
)

cst2 <- ckmr_sim_tib %>%
  mutate(scenario = str_c(mc_method, numerator, denominator, true_relat, sep = "-")) %>%
  left_join(error_types_tib, by = join_by(scenario))
  

source("R/shift_legend.R")


# first do the importance sampling ones
g <- ggplot(cst2 %>% filter(mc_method == "IS"), aes(x = FNR, y = FPR, colour = `Error Category`, linetype = `Error Category`)) +
  geom_line() +
  #geom_segment(aes(x = FNR, xend = FNR, y = FPR - 2 * se, yend = FPR + 2 * se)) +
  facet_wrap(~ ckmr_sim_group, nrow = 4) +
  scale_y_continuous(trans = "log10") +
  theme_bw() + 
  theme(legend.direction = "horizontal") +
  xlab("False Negative Rate") +
  ylab("False Positive Rate (Log10-scaled)") +
  guides(
    colour = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2
      )
  ) +
  guides(
    linetype = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2
      )
  )
  
a <- grid.arrange(shift_legend(g))
```

Now, let's look at the vanilla ones:
```{r}
g2 <- ggplot(
  cst2 %>% filter(mc_method == "vanilla" & FPR > 0 & FPR - 2 * sqrt(FPR * (1 - FPR) / 5e4) > 0.8e-05), 
  aes(x = FNR, y = FPR)) +
  geom_segment(
    aes(
      x = FNR, 
      xend = FNR,
      y = FPR - 2 * sqrt(FPR * (1 - FPR) / 5e4),
      yend = FPR + 2 * sqrt(FPR * (1 - FPR) / 5e4),
      colour = `Error Category`
    ),
    linewidth = 0.2,
    show.legend = FALSE
  ) +
  geom_line(aes(colour = `Error Category`, linetype = `Error Category`)) +
  facet_wrap(~ ckmr_sim_group, nrow = 4) +
  scale_y_continuous(trans = "log10") +
  theme_bw() + 
  theme(legend.direction = "horizontal") +
  xlab("False Negative Rate") +
  ylab("False Positive Rate (Log10-scaled)") +
  guides(
    colour = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2),
    linetype = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2)
  ) +
  theme(legend.direction = "horizontal")

a2 <- grid.arrange(shift_legend(g2))

```

Then cowplot it:
```{r}
Both <- cowplot::plot_grid(a, a2, nrow = 1, labels = c("a)", "b)"))

ggsave(Both, filename = output_list$ckmr_figure, width = 12, height = 7)


# let's crop that down for use, too
CALL <- paste("pdfcrop ", output_list$ckmr_figure, collapse = " ")
system(CALL)

file.rename(from = output_list$ckmr_figure_crop, to = output_list$ckmr_figure_tex)
```


# Logl Ratio Plot Comparisons

Neil suggested, and Carlos and I agreed, that one way to see they improvement in
relationship inference obtained by using multiallelic microhaps is to look at the
separation of the different relationship log-likelihood ratios when using just the
best (MAF closest to 0.5) SNP from each locus, or when using all the SNPs/alleles.
We deciced to do this for the hatchery populations in California, as well as the
winter run.  I am going to implement this in a few functions, each of which operate
on the one of the ckmr_sim_nests.

```{r}
#' function to get just the best SNP out of each microhap
#' 
#' This works on a single collection at a time.
#' @param X a tibble like that nested in a single row of ckmr_sim_nests
#' @return Returns a tibble like X, but with just the best SNP from
#' each amplicon (note that it might also drop some monomorphic amplicons).
retain_top_snp <- function(X) {
  # first, get the microhaps in long format
  tmp <- X %>%
    select(-(repunit:sample_type)) %>%
    pivot_longer(
      -indiv,
      names_to = c("Locus", "gene_copy"),
      values_to = "Allele",
      names_pattern = "^(.*)_([12])$"
    ) %>%
    filter(!is.na(Allele))
  
  # then explode it out to individual SNPs
  exploded <- tmp %>%
    mutate(
      snp_num = map(Allele, function(x) 1:nchar(x)),
      snp_alle = map(Allele, function(x) strsplit(x, "")[[1]])
    ) %>%
    unnest(cols = c(snp_num, snp_alle))
  
  # now, get the highest maf snp at each locus in a tibble
  highest_mafs <- exploded %>%
    count(Locus, snp_num, snp_alle) %>%
    group_by(Locus, snp_num) %>%
    mutate(af = n / sum(n)) %>%
    filter(af <= 0.5) %>%
    ungroup() %>%
    arrange(Locus, desc(af)) %>%
    group_by(Locus) %>%
    slice(1) %>%
    ungroup()
  
  # then pull those out of the "exploded" variable with a semi_join
  # and put them back into wide format, left join it onto the meta
  # data
  ret <- exploded %>%
    semi_join(highest_mafs, by = join_by(Locus, snp_num)) %>%
    select(indiv, Locus, gene_copy, snp_alle) %>%
    pivot_wider(
      names_from = c(Locus, gene_copy),
      values_from = snp_alle,
      names_sep = "_"
    ) %>%
    left_join(
      X %>% select(indiv, repunit, collection, sample_type),
      .,
      by = join_by(indiv)
    )
  
  ret
    
}

```

So, that is how we pick out the top SNP.  But now we also need a function that is
going to give us the set of all the simulated logl-ratios that we need (whether it
is all the microhap alleles or just the top SNPs).  We can build off of what
we did in a function above.
```{r}
get_logl_rats <- function(X, GC2 = gen_coords) {
  
  Y <- ckmr_afreqs_ready(X, GC2)
  
  C <- ckmr_create(Y) 
  
  # throttle text output to console
  options(CKMRsim.discard_stdout = TRUE)
  options(CKMRsim.linkage_verbosity = 0)
  
  # Simulate some Q_ij's. Suppress output messages that the CKMRsim package
  # produces
  Q_link <- ckmr_simQ(C) #%>% suppressMessages()
  
  # now extract the logl_ratios for PO vs U and return those
  extract_logls(Q_link, numer = c(PO = 1), denom = c(U = 1))
}
```

And, with those two functions, it would appear that we have eveything we need to get the
simulation results we will want.  Once again we will mclapply over the populations.

```{r}
# collections / groups we want to do
pops <- c("ck-FRH", "ck-IGH", "ck-SRW", "ck-TRH")

# let's put the microhaps and the best SNPs together in a long format.
input_tibbles <- bind_rows(
  ckmr_sim_nests %>%
    filter(ckmr_sim_group %in% pops) %>%
    mutate(condition = "microhaps", .before = ckmr_sim_group),
  ckmr_sim_nests %>%
    filter(ckmr_sim_group %in% pops) %>%
    mutate(tops = map(data, retain_top_snp)) %>%
    mutate(data = tops) %>%
    select(-tops) %>%
    mutate(condition = "top_snps", .before = ckmr_sim_group)
)

Qsims <- mclapply(input_tibbles$data, get_logl_rats, mc.cores = 8)

AllSims <- tibble(
  condition = input_tibbles$condition,
  ckmr_sim_group = input_tibbles$ckmr_sim_group,
  Qsims = Qsims
) %>% 
  unnest(Qsims) %>%
  select(condition, ckmr_sim_group, true_relat, logl_ratio)
```

Now, we can plot all of those.  Let's see if we can get all four onto one page easily enough.
```{r}
asg <- ggplot(AllSims, aes(x = logl_ratio, fill = true_relat)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ ckmr_sim_group + condition, ncol = 1) +
  theme_bw() +
  labs(fill = "True\nRelationship") +
  xlab("PO vs U Log-likelihood Ratio")

# this fails for some reason (ggsave never returns)
# ggsave(asg, path = "boing.png", height = 15, width = 9)

# So, instead I just print the thing in the Rstudio window and export it
# at size 13" high by 10" wide. Then I moved it to where it belongs in the tex directory.
asg
```
