---
title: "Assessing Power of the California Microhap Baseline for PBT and relationship inference"
author: "Eric C. Anderson"
date: "Last Updated: `r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
start_time <- Sys.time()
```



```{r}
if(exists("snakemake")) {
  input_list <- snakemake@input
  output_list <- snakemake@output
} else {
  input_list <- list(
    final_baseline = "data/subRoSA_baseline_rubias_FEB2024_w_mixture_revised.csv",
    pop_labels = "inputs/reference-collection-names.csv",
    locus_info = "inputs/ChinookFullPanelLociTable_Feb2024Updated.xlsx"
  )
  output_list <- list(
    ckmr_figure = "results/ckmr-sim-eval/fpr-fnr-figure.pdf",
    ckmr_figure_crop = "results/ckmr-sim-eval/fpr-fnr-figure-crop.pdf",
    ckmr_figure_tex = "tex/images/fpr-fnr-figure-crop.pdf"
  )
}

# you can create the necessary output directories like this:
dump <- lapply(output_list, function(x)
  dir.create(dirname(x), recursive = TRUE, showWarnings = FALSE)
)
```


## Wrangle the data

```{r}
library(tidyverse)
library(CKMRsim)
library(readxl)
library(parallel)
library(grid)
library(gridExtra)

# get the full baseline with the new markers, etc.  We will toss out some
# non-winter Sacto fish of unknown provenance
full_base <- read_csv(input_list$final_baseline) %>%
  filter(collection != "SacNonW")


# read the pop labels for proper sorting
pop_labels <- read_csv(input_list$pop_labels)

# rename those collections and repunits
full_base2 <- full_base %>%
  rename(old_name = collection) %>%
  select(-repunit) %>%
  left_join(pop_labels %>% select(old_name, collection, repunit, ckmr_sim_group), by = join_by(old_name)) %>%
  select(-old_name) %>%
  select(indiv, repunit, collection, sample_type, ckmr_sim_group, everything())


# after that, we can nest things into separate ckmr_sim_groups
ckmr_sim_nests <- full_base2 %>%
  group_by(ckmr_sim_group) %>%
  nest()


# now, we also want to get the genome positions of things.
# we take its position to be the start position of the amplicon
gen_coords <- read_excel(input_list$locus_info) %>%
  select(Locus, AmpliconGenomveV2Location) %>%
  separate(AmpliconGenomveV2Location, into = c("Chrom", "pos_str"), sep = ":") %>%
  separate(pos_str, into = c("Start", "Stop"), sep = "-", convert = TRUE) %>%
  rename(Pos = Start) %>%
  select(-Stop) %>%
  arrange(Chrom, Pos)





```


## Now, a series of functions to operate on each nest and do CKMRsim things

```{r}
#' @param X a tibble like that nested in a single row of ckmr_sim_nests
#' @param GC2 essentially the gen_coords object from above
ckmr_afreqs_ready <- function(X, GC2) {
  tmp <- X %>%
    select(-(repunit:sample_type)) %>%
    pivot_longer(
      -indiv,
      names_to = c("Locus", "gene_copy"),
      values_to = "Allele",
      names_pattern = "^(.*)_([12])$"
    ) %>%
    filter(!is.na(Allele)) %>%
    count(Locus, Allele) %>%
    group_by(Locus) %>%
    filter(n() > 1) %>% # filter out monomorphic loci
    mutate(
      Freq = n / sum(n),
    ) %>%
    ungroup() %>%
    left_join(GC2, by = join_by(Locus)) %>%
    select(Chrom, Pos, Locus, Allele, Freq) %>%
    arrange(Pos, desc(Freq)) 
  
  no_pos_posse <- tmp %>% 
    filter(is.na(Chrom))
  
  if(nrow(no_pos_posse) > 0) {
    warning("Some loci without genomic positions: ", paste(unique(no_pos_posse$Locus), collapse = ", "), "\n\n")
    warning("Those loci were dropped, and the analysis should survive, but you should see what's up!")
  }
  
  # then, return thing without the no_pos_posse markers
  tmp %>%
    filter(!is.na(Chrom)) %>%
    mutate(
      AlleIdx = NA,
      LocIdx = NA
    ) %>%
    CKMRsim::reindex_markers()
  
}


# here is one to create a ckmr object.
# Y is simply the output of ckmr_afreqs_ready()
ckmr_create <- function(Y) {
  create_ckmr(
    D = Y,
    kappa_matrix = kappas[c("PO", "FS", "HS", "AN", "U"), ],
    ge_mod_assumed = ge_model_TGIE,
    ge_mod_true = ge_model_TGIE,
    ge_mod_assumed_pars_list = list(epsilon = 0.005),
    ge_mod_true_pars_list = list(epsilon = 0.005)
  )
}


# This does the simulate_Qij step and then also estimates the FPRs.
ckmr_simQ <- function(C, unlinked = FALSE, num_mc_samples = 1e5) {
  simulate_Qij(
    C,
    reps = num_mc_samples,  # 100,000 monte carlo samples by default
    calc_relats = c("PO", "FS", "HS", "AN", "U"),
    sim_relats = c("PO", "FS", "HS", "AN", "U"),
    unlinked = unlinked,
    pedigree_list = pedigrees
  )
}


```


And here is a function that does the above and then spits out some FPRs and FNRs:
```{r}

get_FPRs_and_FNRs <- function(X, GC2 = gen_coords) {
  
  Y <- ckmr_afreqs_ready(X, GC2)
  
  C <- ckmr_create(Y) 
  
  # throttle text output to console
  options(CKMRsim.discard_stdout = TRUE)
  options(CKMRsim.linkage_verbosity = 0)
  
  # Simulate some Q_ij's. Suppress output messages that the CKMRsim package
  # produces
  Q_link <- ckmr_simQ(C) #%>% suppressMessages()
  Q_unl <- ckmr_simQ(C, unlinked = TRUE) #%>% suppressMessages()
  
  # get FPRs and FNRs for a variety of relationships.  Return in a big tibble
  
  ret <- list(
    # first for resolving unrelated individuals from PO and FS (and HS, for which there is no hope!)
    all_v_unrel = mc_sample_simple(
      Q = Q_unl,
      Q_for_fnrs = Q_link,
      nu = c("PO", "FS", "HS"),
      de = "U",
      tr = "U",
      method = "IS",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    # then, vanilla MCMC to see how readily we can distinguish FS from PO,
    # and then, of course FS from HS and PO from A, etc.
    po_vs_fs = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "FS",
      tr = "FS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    fs_vs_po = mc_sample_simple(
      Q = Q_link,
      nu = c("FS"),
      de = "PO",
      tr = "PO",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    fs_vs_hs = mc_sample_simple(
      Q = Q_link,
      nu = c("FS"),
      de = "HS",
      tr = "HS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    po_vs_hs = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "HS",
      tr = "HS",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    ),
    po_vs_an = mc_sample_simple(
      Q = Q_link,
      nu = c("PO"),
      de = "AN",
      tr = "AN",
      method = "vanilla",
      FNRs = seq(0.01, 0.3, by = 0.01)
    )
  ) %>%
    bind_rows(.id = "what_it_was")
  
  ret
}


```


I tried ripping through everything using furrr::future_map() but that did not
actually do it in parallel.  So we are going to just mclapply it:

```{r}
set.seed(5)
tmp_list <- mclapply(
  X = ckmr_sim_nests$data, 
  FUN = function(x) get_FPRs_and_FNRs(x),
  mc.cores = 8
)

ckmr_sim_results <- tibble(
  ckmr_sim_nests,
  fprs = tmp_list
)
```


## Make a plot with all those results

```{r}
# unnest it
ckmr_sim_tib <- ckmr_sim_results %>%
  select(-data) %>%
  unnest(fprs) %>%
  ungroup()

# just print out the different scenarios simulated
ckmr_sim_tib %>%
  distinct(mc_method, numerator, denominator, true_relat)
```


Now, make a figure of those results.

```{r}
# first, try a simple way of categorizing the errors
error_types_tib <- tribble(
  ~"scenario", ~"Error Category",
  "IS-FS-U-U", "Mistaking U for FS",
  "IS-HS-U-U", "Mistaking U for HS",
  "IS-PO-U-U", "Mistaking U for PO",
  "vanilla-FS-HS-HS", "Mistaking HS for FS",
  "vanilla-FS-PO-PO", "Mistaking PO for FS",
  "vanilla-PO-AN-AN", "Mistaking AN for PO",
  "vanilla-PO-FS-FS", "Mistaking FS for PO",
  "vanilla-PO-HS-HS", "Mistaking HS for PO"
)

cst2 <- ckmr_sim_tib %>%
  mutate(scenario = str_c(mc_method, numerator, denominator, true_relat, sep = "-")) %>%
  left_join(error_types_tib, by = join_by(scenario))
  

source("R/shift_legend.R")


# first do the importance sampling ones
g <- ggplot(cst2 %>% filter(mc_method == "IS"), aes(x = FNR, y = FPR, colour = `Error Category`, linetype = `Error Category`)) +
  geom_line() +
  #geom_segment(aes(x = FNR, xend = FNR, y = FPR - 2 * se, yend = FPR + 2 * se)) +
  facet_wrap(~ ckmr_sim_group, nrow = 4) +
  scale_y_continuous(trans = "log10") +
  theme_bw() + 
  theme(legend.direction = "horizontal") +
  xlab("False Negative Rate") +
  ylab("False Positive Rate (Log10-scaled)") +
  guides(
    colour = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2
      )
  ) +
  guides(
    linetype = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2
      )
  )
  
a <- grid.arrange(shift_legend(g))
```

Now, let's look at the vanilla ones:
```{r}
g2 <- ggplot(
  cst2 %>% filter(mc_method == "vanilla" & FPR > 0 & FPR - 2 * sqrt(FPR * (1 - FPR) / 5e4) > 0.8e-05), 
  aes(x = FNR, y = FPR)) +
  geom_segment(
    aes(
      x = FNR, 
      xend = FNR,
      y = FPR - 2 * sqrt(FPR * (1 - FPR) / 5e4),
      yend = FPR + 2 * sqrt(FPR * (1 - FPR) / 5e4),
      colour = `Error Category`
    ),
    linewidth = 0.2,
    show.legend = FALSE
  ) +
  geom_line(aes(colour = `Error Category`, linetype = `Error Category`)) +
  facet_wrap(~ ckmr_sim_group, nrow = 4) +
  scale_y_continuous(trans = "log10") +
  theme_bw() + 
  theme(legend.direction = "horizontal") +
  xlab("False Negative Rate") +
  ylab("False Positive Rate (Log10-scaled)") +
  guides(
    colour = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2),
    linetype = guide_legend(
      title.position = "top",
      label.position = "bottom",
      nrow = 2)
  ) +
  theme(legend.direction = "horizontal")

a2 <- grid.arrange(shift_legend(g2))

```

Then cowplot it:
```{r}
Both <- cowplot::plot_grid(a, a2, nrow = 1, labels = c("a)", "b)"))

ggsave(Both, filename = output_list$ckmr_figure, width = 12, height = 7)


# let's crop that down for use, too
CALL <- paste("pdfcrop ", output_list$ckmr_figure, collapse = " ")
system(CALL)

file.rename(from = output_list$ckmr_figure_crop, to = output_list$ckmr_figure_tex)
```
