---
title: "Assessing Power of the California Microhap Baseline for GSI (and calculating Fst)"
author: "Eric C. Anderson"
date: "Last Updated: `r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
bibliography: "`r here::here('references.bib')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
knitr::opts_knit$set(root.dir = here::here())
start_time <- Sys.time()

USING_SNAKEMAKE <- FALSE
NEG_USING_SMK <- TRUE
if(exists("snakemake")) {
  USING_SNAKEMAKE <- TRUE
  NEG_USING_SMK <- FALSE
}
```

```{r rmd_snakemake_hacks, include=FALSE, eval=USING_SNAKEMAKE}
# currently, this block does not get evaluated, while developing,
# but later when we snakemake-ize it all, we will evaluate it.
if(USING_SNAKEMAKE) {
  input_list <- snakemake@input
  output_list <- snakemake@output
}
```

# Input and Output Paths

```{r input_bypass, include=NEG_USING_SMK, eval=NEG_USING_SMK}
# inputs:
input_list <- list(
  final_baseline = "data/cali-chinook-baseline.rds",
  pop_labels = "inputs/reference-collection-names.csv",
  map_notations = "inputs/map-notations.tsv"
)
# outputs:
output_list <- list(
  assig_table = "results/GSI_and_Fst/assignment-table-full-baseline.pdf",
  fst_table = "results/GSI_and_Fst/full-baseline-but-no-lfar-Fst-table.pdf",
  assig_table_lfar_all = "results/GSI_and_Fst/assignment-table-full-baseline-plus-lfar.pdf",
  assig_table_lfar_no_miss = "results/GSI_and_Fst/assignment-table-full-baseline-plus-lfar-and-everyone-has-the-lfar.pdf"
)
# you can create the necessary output directories like this:
dump <- lapply(output_list, function(x)
  dir.create(dirname(x), recursive = TRUE, showWarnings = FALSE)
)
```


# Introduction

Here we assess power of the baseline for population assignment

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(rubias)
library(cowplot)
library(hierfstat)


# get the full baseline with the new markers, etc.  We will toss out some
# non-winter Sacto fish of unknown provenance
full_base <- read_rds(input_list$final_baseline) %>%
  filter(collection != "SacNonW")


# read the pop labels for proper sorting
pop_labels <- read_csv(input_list$pop_labels)

# rename those collections and repunits
full_base2 <- full_base %>%
  rename(old_name = collection) %>%
  select(-repunit) %>%
  left_join(pop_labels %>% select(-run_timing_group), by = join_by(old_name)) %>%
  select(-old_name) %>%
  select(indiv, repunit, collection, sample_type, everything())
  
# finally, get the order of collections and repunits we want
collection_order <- unique(pop_labels$collection)
```


# Make a table summary of all the samples

I would like to break things down by general sampling location, run type, number of samples,
month-range of sampling, and range of years.
```{r}
map_notations <- read_tsv(input_list$map_notations, comment = "#")
full_base2 %>%
  count(repunit, collection) %>%
  left_join
```




# Do the self-assignment

In this round, we go directly to assigning to repunit, and then to the max-likelihood
collection within that repunit.

```{r}
full_sa <- self_assign(full_base2, gen_start_col = 5)
```

```{r}
top_ass <- full_sa %>%
  group_by(indiv, collection, repunit, inferred_repunit) %>%
  mutate(repu_sclike = sum(scaled_likelihood)) %>%
  group_by(indiv) %>%
  filter(repu_sclike == max(repu_sclike)) %>%
  arrange(indiv, desc(scaled_likelihood)) %>%
  slice(1) %>%
  ungroup() %>%
  mutate(coll_f = factor(collection, levels = collection_order))
```

And, once again, we want to investigate the ones that are in the wrong repunit, and look at their
scaled_repu_likelihoods, the others.
```{r}
source("R/colors.R")
ta_corr <- top_ass %>%
  filter(repunit == inferred_repunit)
ta_wrong <- top_ass %>%
  filter(repunit != inferred_repunit) %>%
  arrange(collection, repu_sclike) %>%
  group_by(collection) %>%
  mutate(y = 190 + (70/9) * 1:n())

ggplot() +
  geom_histogram(
    data = ta_corr, 
    mapping = aes(x = repu_sclike, fill = inferred_repunit)
  ) +
  geom_point(
    data = ta_wrong,
    mapping = aes(x = repu_sclike, y = y, fill = inferred_repunit),
    size = 3, 
    shape = 21
  ) +
  facet_wrap(~coll_f, ncol = 3) +
  scale_fill_manual(values = repunit_colors)
```
Which looks to me like there are really only 7 here that we are not getting right.
Those others we will filter out and make a table of them:

```{r}
tafilt <- top_ass %>%
  filter(!(repunit != inferred_repunit & repu_sclike > 0.99))
```

Here we calculate the number of correctly and incorrectly assigned fish:
```{r}
tafilt %>%
  mutate(correct = repunit == inferred_repunit) %>%
  count(correct) %>%
  mutate(fract = n / sum(n))
```

And now we will make a table of those:
```{r}
# get the function
source("R/taf-prep.R")
source("R/table-as-figure.R")

# get the RC_groups
RC_groups <- pop_labels %>%
  select(-old_name) %>%
  distinct() %>%
  rename(external_group = run_timing_group, internal_group = repunit, label = collection) %>%
  select(external_group, internal_group, label)

X2 <- tafilt %>%
  mutate(
    collection_f = factor(collection, levels = collection_order),
    inferred_coll_f = factor(inferred_collection, levels = collection_order)
  ) %>%
  count(collection_f, inferred_coll_f, .drop = FALSE) %>%
  taf_prep()

# get the result
TAF2 <- table_as_figure(
  X = X2, 
  RC_groups = RC_groups,
  external_colors = run_time_colors,
  internal_colors = repunit_colors, 
  plot_margins = c(1, 0.1, 0.7, 0.1)
)

# and plot it
g <- plot_grid(
  TAF2$full_plot,
  plot_grid(
    get_legend(TAF2$for_external_legend),
    get_legend(TAF2$for_internal_legend),
    nrow = 1
  ),
  nrow = 2,
  rel_heights = c(7,3)
)

g
```

That is a considerable improvement. Let's write it out:
```{r}
ggsave(g, filename = output_list$assig_table, width = 8, height = 10)
```


# Calculating Fst between the collections from the microhaplotype markers

We use the 'hierfstat' package to get the pairwise
$F_\mathrm{ST}$ values (Weir & Cockerham method) between the collections from these microhaplotype data.

In order to do this we need to convert the data to a lumped format.
This means making integers of the alleles and then catenating them.
One locus has 11 allele, so we should use two digits for each allele.  We drop the
LFAR from this, because those were chosen specifically to be weird in the late fall.
```{r}
full_base_long <- full_base2 %>% 
  select(-starts_with("NC_037130.1")) %>%  # drop the LFARs
  mutate(
    Pop = as.integer(factor(collection, levels = collection_order)),
    .before = collection
  ) %>%
  select(-repunit, -collection, -sample_type) %>%
  pivot_longer(
    cols = c(-indiv, -Pop),
    names_to = c("locus", "gene_copy"),
    names_pattern = "^(.*)_([12])$"
  )

hfs_ref_long <- full_base_long %>%
  group_by(locus) %>%
  mutate(
    alle_int =  sprintf("%02d", as.integer(factor(value)))
  ) %>%
  ungroup() %>%
  select(-value)

# then we can lump the alleles 
hfs_ref_wide <- hfs_ref_long %>%
  group_by(indiv, Pop, locus) %>%
  summarise(geno = str_c(alle_int[1], alle_int[2])) %>%
  ungroup() %>%
  mutate(geno = ifelse(str_detect(geno, "NA"), NA_character_, geno)) %>%
  mutate(geno = as.integer(geno)) %>%
  pivot_wider(
    names_from = c(locus),
    values_from = geno
  ) %>%
  arrange(Pop, indiv)

hfstat_dat <- hfs_ref_wide %>% 
  select(-indiv) %>%
  as.data.frame()


FST <- pp.fst(dat = hfstat_dat, diploid = TRUE)

# let's also bootstrap that:
FST_boot <- boot.ppfst(
  dat = hfstat_dat,
  nboot = 1000,
  quant = c(0.025,0.975),
  diploid = TRUE
)


# now, get the values out of it and put them in the upper diagonal
# of a matrix for plotting with the WGS values.
fst_mat <- FST$fst.pp 
colnames(fst_mat) <- collection_order
```


```{r}
  
all_values_tib <- fst_mat %>%
  as_tibble() %>%
  mutate(row_label = collection_order, .before = SRW) %>%
  pivot_longer(
    -row_label, 
    names_to = "col_label",
    values_to = "fst"
  )

# to get it to the right format we make it look like rubias
# output and the pipe it into taf_prep()
upper_tri_fst <- all_values_tib %>%
  filter(!is.nan(fst)) %>%
  mutate(
    collection_f = factor(row_label, levels = collection_order),
    inferred_coll_f = factor(col_label, levels = collection_order)
  ) %>% 
  select(-row_label, -col_label) %>%
  mutate(n = sprintf("%0.3f", fst)) %>%
  select(-fst) %>%
  taf_prep()
  
 
```


Now that we have the `upper_tri_fst` values in the right format, we just need
to add the WGS values to the lower triangle part of the matrix.  


# Adding the WGS Fst values and making a figure

```{r}
# for now I am just going to put the WGS Fst's into the lower diagonal, but I think it will be better, ultimately,
# to but the bootstrapped CI's in there.
wgs_mat <- read_rds("../anderson-et-al-chinook-ecotypic-genetic-architecture/outputs/001/full-wgs-fst-mat.rds")

# once again, make it looks like rubias output and taf_prep() it.
lower_tri_diag <- wgs_mat %>%
  mutate(
    collection_f = factor(pop1_f, levels = collection_order),
    inferred_coll_f = factor(pop2_f, levels = collection_order),
    n = fst
  ) %>%
  select(collection_f, inferred_coll_f, n) %>%
  complete(collection_f, inferred_coll_f) %>%
  filter(as.integer(collection_f) >= as.integer(inferred_coll_f)) %>%  # this gets lower tri + diagonal
  taf_prep()
  

# then we put those together and make a figure
full_fst <- bind_rows(
  upper_tri_fst,
  lower_tri_diag
) %>%
  arrange(row_label, col_label)


# get the result
TAF_FST <- table_as_figure(
  X = full_fst, 
  RC_groups = RC_groups,
  external_colors = run_time_colors,
  internal_colors = repunit_colors,
  Xs_on_diagonal = TRUE,
  plot_margins = c(0.7, 0.1, 0.1, 0.1)
)


# and plot it
TAF_FST$full_plot


```

And we can save that too:
```{r}
ggsave(TAF_FST$full_plot, file = output_list$fst_table, width = 6, height = 5.1)
```

# Add the LFAR markers to that

Anthony compiled the LFAR markers for the baseline fish.  Not every fish in the baseline
was typed at the LFAR markers.  So, let us see which ones that includes.
```{r}
lfar <- read_csv(input_list$lfar_base)
```

As we saw previously, the loci that we are interested in here are:
```
"NC_037130.1:1062935-1063235",
"NC_037130.1:828619-828919",
"NC_037130.1:864908-865208"
```

However, the 828619 gobbles up reads that don't all map to the right place and
turns out not to be super informative, so we will drop it.

Also, we can call these things as SNPs, not microhaps, which we will do.  The Canonical
Variation file in the snakemake workflow tells us which position is the target SNP in each:

```{r}
focal_loci <- c(
  "NC_037130.1:1062935-1063235",  # target SNP is the second one (position 151 in the amplicon)
  "NC_037130.1:864908-865208"     # target SNP is the first one (position 151 in the amplicon)
)

# so we can pick those out:
lfar_focal <- lfar[,c("Sample_ID", paste(rep(focal_loci, each = 2), c("_1", "_2"), sep = ""))]

# then we will pick out just the target SNPs, too
lfar_focal[, 2] <- str_sub(lfar_focal[[2]], 2, 2)
lfar_focal[, 3] <- str_sub(lfar_focal[[3]], 2, 2)
lfar_focal[, 4] <- str_sub(lfar_focal[[4]], 1, 1)
lfar_focal[, 5] <- str_sub(lfar_focal[[5]], 1, 1)
```


We will left join this onto the baseline by the NMFS_DNA_ID:
```{r}
full_base_lfar <- full_base2 %>%
  left_join(lfar_focal, by = join_by(indiv == Sample_ID))
```

Quickly, let's count up how many individuals we have typed at all these loci.
```{r}
lfar_check <- full_base_lfar[, c("indiv", "repunit", "collection", paste(focal_loci, 1, sep = "_"))] %>%
  mutate(Baseline = "Baseline") %>%
  pivot_longer(-(indiv:collection), names_to = "set") %>%
  mutate(HasData = !is.na(value))

  

lfar_check %>%
  group_by(repunit, collection, set) %>%
  summarise(
    num_fish_with_genos = sum(HasData)
  ) %>%
  pivot_wider(names_from = set, values_from = num_fish_with_genos)
  
  
```
OK! That is great.  We have genotyped pretty much everyone at these LFAR markers except for about 50 of the
FRHS and 10 of the MDF.  If need be would could toss fish that don't have genotypes at any LFAR markers
when we make the assignment table.  Let's get a tibble of baseline individuals telling us whether or not
they have data for at least one of the LFAR markers:
```{r}
at_least_one_lfar <- lfar_check %>%
  filter(set != "Baseline") %>%
  group_by(indiv) %>%
  summarise(at_least_one_lfar = any(HasData == TRUE))

# just see how many there are in total
at_least_one_lfar %>%
  count(at_least_one_lfar)
```
OK! We will compute the assignment table with and without those 66.


## Self-assignment


```{r}
sa_lfar_all <- self_assign(full_base_lfar, gen_start_col = 5)

top_ass_lf <- sa_lfar_all %>%
  group_by(indiv, collection, repunit, inferred_repunit) %>%
  mutate(repu_sclike = sum(scaled_likelihood)) %>%
  group_by(indiv) %>%
  filter(repu_sclike == max(repu_sclike)) %>%
  arrange(indiv, desc(scaled_likelihood)) %>%
  slice(1) %>%
  ungroup() %>%
  mutate(coll_f = factor(collection, levels = collection_order))
```


## Checking for individuals sampled into the wrong collections

We investigate the ones that are in the wrong repunit, and look at their
scaled_repu_likelihoods, to the others.
```{r}
source("R/colors.R")
ta_corr_lf <- top_ass_lf %>%
  filter(repunit == inferred_repunit)
ta_wrong_lf <- top_ass_lf %>%
  filter(repunit != inferred_repunit) %>%
  arrange(collection, repu_sclike) %>%
  group_by(collection) %>%
  mutate(y = 190 + (70/9) * 1:n())

ggplot() +
  geom_histogram(
    data = ta_corr_lf, 
    mapping = aes(x = repu_sclike, fill = inferred_repunit)
  ) +
  geom_point(
    data = ta_wrong_lf,
    mapping = aes(x = repu_sclike, y = y, fill = inferred_repunit),
    size = 3, 
    shape = 21
  ) +
  facet_wrap(~coll_f, ncol = 3) +
  scale_fill_manual(values = gen_bkgrnd_colors)
```
This is much like it was before, however one CHLF fish that was inferred as a spring
run is now inferred as a CHLF.

We toss those 6 that are assigned quite strongly (> 0.98) to a repunit
that they were not sampled in. (Again, the winter-run are clearly true winter
run sampled in the fall or spring collections, and the same is probably true
for MDS-collected fish that are really fall run. We could follow the latter
up with the rosa markers.)

```{r}
ta_lf_filt <- top_ass_lf %>%
  filter(!(repunit != inferred_repunit & repu_sclike > 0.98))

# get the total fraction of assigned vs misassigned fish
ta_lf_filt %>%
  mutate(correct = repunit == inferred_repunit) %>%
  count(correct) %>%
  mutate(fract = n / sum(n))
```
Pretty good.

But, what we really want to see if the table for the collections, to see if we can distinguish
late-fall from fall run any better.


## Assignment table with all the fish

```{r}
# get the function
source("R/taf-prep.R")
source("R/table-as-figure.R")

# get the RC_groups
RC_groups <- pop_labels %>%
  select(-old_name) %>%
  distinct() %>%
  rename(external_group = run_timing_group, internal_group = repunit, label = collection) %>%
  select(external_group, internal_group, label)

X2 <- ta_lf_filt %>%
  mutate(
    collection_f = factor(collection, levels = collection_order),
    inferred_coll_f = factor(inferred_collection, levels = collection_order)
  ) %>%
  count(collection_f, inferred_coll_f, .drop = FALSE) %>%
  taf_prep()

# get the result
TAF2_lf <- table_as_figure(
  X = X2, 
  RC_groups = RC_groups,
  external_colors = run_time_colors,
  internal_colors = gen_bkgrnd_colors, 
  plot_margins = c(1, 0.1, 0.7, 0.1)
)

# and plot it
g <- plot_grid(
  TAF2_lf$full_plot,
  plot_grid(
    get_legend(TAF2_lf$for_external_legend),
    get_legend(TAF2_lf$for_internal_legend),
    nrow = 1
  ),
  nrow = 2,
  rel_heights = c(7,3)
)

g
```


```{r}
ggsave(g, filename = output_list$assig_table_lfar_all, width = 6, height = 8)
```

## Assignment table with only the fish that have at least one-non-missing genotype among the 3 LFAR genotypes.  

We can just filter out fish that don't have a non-missing genotype amongst the three LFARs and call it good.

```{r}
X2_alolf <- ta_lf_filt %>%
  semi_join(at_least_one_lfar %>% filter(at_least_one_lfar), by = join_by(indiv)) %>%
  mutate(
    collection_f = factor(collection, levels = collection_order),
    inferred_coll_f = factor(inferred_collection, levels = collection_order)
  ) %>%
  count(collection_f, inferred_coll_f, .drop = FALSE) %>%
  taf_prep()

# get the result
TAF2_alolf <- table_as_figure(
  X = X2_alolf, 
  RC_groups = RC_groups,
  external_colors = run_time_colors,
  internal_colors = gen_bkgrnd_colors, 
  plot_margins = c(1, 0.1, 0.7, 0.1)
)

# and plot it
g <- plot_grid(
  TAF2_alolf$full_plot,
  plot_grid(
    get_legend(TAF2_alolf$for_external_legend),
    get_legend(TAF2_alolf$for_internal_legend),
    nrow = 1
  ),
  nrow = 2,
  rel_heights = c(7,3)
)

g
```

```{r}
ggsave(g, filename = output_list$assig_table_lfar_no_miss, width = 6, height = 8)
```

OK, that is good to see.  The missassignments to or from CHLF are *not* because
they don't have data at the LFAR.  So, we can just use the full data set.


